# Объяснение Работы Детекторов Аномалий

Этот документ подробно описывает, как работает каждый из детекторов аномалий, реализованных в проекте, включая используемые признаки, процесс обучения и механизм обнаружения аномалий.

## Общий Пайплайн (Управляется `api/anomalies.py`)

Перед детальным рассмотрением каждого детектора важно понимать общий конвейер обработки данных при обучении и обнаружении:

1.  **Загрузка данных:** Функция `common.load_data_from_db` извлекает данные `OrderItem`. Для большинства операций (обучение, детекция) она также присоединяет (`load_associations=True`) связанные данные из таблиц `Order`, `Product`, `Customer`, `Seller`, `OrderPayment`, `OrderReview` и `ProductCategoryNameTranslation`.
2.  **Генерация Признаков (Feature Engineering):** Функция `common.engineer_features` *может* быть вызвана для создания дополнительных признаков. 
    *   **Текущая реализация:** Добавляет только признак `price_deviation_from_category_mean`.
    *   **Условие вызова:** Вызывается, если тип детектора **не** 'graph' **и** если для данного типа детектора (statistical, isolation_forest, autoencoder, vae) в конфигурации **не** указаны базовые признаки, либо указанные базовые признаки отсутствуют в загруженных данных.
3.  **Инициализация Детектора:** Создается объект соответствующего класса детектора (`StatisticalDetector`, `IsolationForestDetector`, etc.), используя параметры, переданные в конфигурации запроса (`model_config`).
4.  **Обучение (Эндпоинт `/train`):
    *   Вызывается метод `detector.train(данные)`.
    *   Модель обучается (вычисляются статистики, обучается нейросеть и т.д.).
    *   Внутреннее состояние (параметры модели, статистики, скейлер, порог аномальности, нормализатор min/max скоров) сохраняется в файл с помощью `detector.save_model()`.
5.  **Индивидуальная Детекция (Эндпоинт `/detect`):
    *   Состояние детектора загружается из файла с помощью `detector.load_model()`.
    *   Вызывается метод `detector.detect(данные)`.
    *   Этот метод возвращает Pandas DataFrame с добавленными колонками:
        *   `anomaly_score`: "Сырой" скор аномальности (его природа зависит от детектора: Z-score, ошибка реконструкции и т.д.).
        *   `is_anomaly`: Логический флаг (`True`/`False`), указывающий, считает ли *данный детектор* эту запись аномальной (на основе своего внутреннего порога).
    *   Фоновая задача `detect_anomalies_task` отбирает строки, где `is_anomaly == True`, и сохраняет информацию о них в таблицу `anomalies` базы данных.
6.  **Детекция Ансамблем (Эндпоинт `/detect/ensemble`):
    *   Сервис `EnsembleDetectorService` загружает все детекторы, перечисленные в конфигурации `ENSEMBLE_MODEL_CONFIGS`.
    *   Для каждого детектора вызывается `detector.detect()` для получения сырых скоров (`anomaly_score`).
    *   Каждый сырой скор нормализуется к шкале [0, 1] с помощью `detector.normalize_score()` (используя min/max, сохраненные при обучении).
    *   Нормализованные скоры от всех детекторов комбинируются заданным методом (`average`, `max`, `weighted_average`).
    *   Итоговый комбинированный скор (`ensemble_score`) сравнивается с порогом `ensemble_threshold`, переданным в запросе, для определения финального флага `is_anomaly`.
    *   Результаты (список аномальных записей со всеми скорами) возвращаются пользователю через статус задачи и **не сохраняются** автоматически в БД.

---

## Анализ Работы Каждого Детектора

### 1. `StatisticalDetector` (На основе Z-Score)

*   **Используемые Признаки:**
    *   Работает только с **одним** числовым признаком.
    *   Признак задается параметром `feature` в конфигурации (например, `"feature": "price"`).
    *   Функция `common.engineer_features` для него **не** вызывается.
*   **Обучение (`train`):**
    *   Вычисляет и сохраняет **среднее (`mean`)** и **стандартное отклонение (`std_dev`)** указанного признака на обучающем наборе данных.
    *   Обучает **нормализатор Min-Max** для скоров (на основе абсолютных Z-оценок обучающих данных), чтобы скор можно было привести к шкале [0, 1] для ансамбля.
*   **Детекция (`detect`):**
    *   Для каждой новой точки данных вычисляет ее **абсолютную Z-оценку**: `abs((value - mean) / std_dev)`.
    *   Эта Z-оценка записывается в колонку `anomaly_score`.
*   **Принятие решения (`is_anomaly`):**
    *   Сравнивает вычисленный `anomaly_score` (абсолютный Z-score) с **порогом `threshold`**, который был задан при инициализации детектора (например, `"threshold": 3.0`).
    *   Если `anomaly_score > threshold`, то `is_anomaly` устанавливается в `True`.
    *   **Вывод:** Этот детектор **сам принимает решение** об аномальности на основе заданного порога Z-оценки.

### 2. `IsolationForestDetector`

*   **Используемые Признаки:**
    *   Работает со **списком** числовых признаков.
    *   Список задается параметром `features` в конфигурации (например, `"features": ["price", "freight_value"]`).
    *   Функция `common.engineer_features` для него **не** вызывается (согласно текущей логике API, т.к. базовые признаки `price`, `freight_value` обычно доступны).
    *   Использует `sklearn.preprocessing.StandardScaler` для масштабирования признаков перед подачей в модель.
*   **Обучение (`train`):**
    *   Обучает модель `sklearn.ensemble.IsolationForest` на масштабированных признаках.
    *   Обучает `StandardScaler`.
    *   Обучает **нормализатор Min-Max** для скоров (на основе `model.decision_function()` обучающих данных), чтобы скор можно было привести к шкале [0, 1] для ансамбля.
*   **Детекция (`detect`):**
    *   Применяет обученный `StandardScaler` к новым данным.
    *   Вычисляет "сырой" скор аномальности с помощью `model.decision_function()`. Чем меньше значение, тем более аномальна точка.
    *   Этот сырой скор записывается в `anomaly_score`.
*   **Принятие решения (`is_anomaly`):**
    *   Использует метод `model.predict()`. Этот метод возвращает `-1` для аномалий (выбросов) и `1` для нормальных точек.
    *   Если `model.predict()` вернул `-1`, то `is_anomaly` устанавливается в `True`.
    *   **Вывод:** Этот детектор **сам принимает решение** об аномальности, используя внутренний порог Isolation Forest (определяемый параметром `contamination` или автоматически).

### 3. `AutoencoderDetector`

*   **Используемые Признаки:**
    *   Работает со **списком** числовых признаков.
    *   Список задается параметром `features` в конфигурации (например, `"features": ["price", "freight_value"]`).
    *   Функция `common.engineer_features` для него **не** вызывается.
    *   Использует `StandardScaler`.
*   **Обучение (`train`):**
    *   Обучает нейросеть-автоэнкодер (PyTorch), минимизируя **ошибку реконструкции** (MSE) между входом и выходом.
    *   Обучает `StandardScaler`.
    *   Вычисляет **порог аномальности (`threshold_`)** как `среднее + N * стандартное отклонение` ошибки реконструкции на обучающих данных.
    *   Обучает **нормализатор Min-Max** для скоров (на основе ошибок реконструкции обучающих данных).
*   **Детекция (`detect`):**
    *   Применяет `StandardScaler`.
    *   Пропускает данные через обученный автоэнкодер.
    *   Вычисляет **ошибку реконструкции (MSE)** для каждой точки.
    *   Эта ошибка записывается в `anomaly_score`.
*   **Принятие решения (`is_anomaly`):**
    *   Сравнивает `anomaly_score` (ошибку реконструкции) с порогом `threshold_`, вычисленным при обучении.
    *   Если `anomaly_score >= threshold_`, то `is_anomaly` устанавливается в `True`.
    *   **Вывод:** Этот детектор **сам принимает решение** об аномальности на основе порога ошибки реконструкции.

### 4. `VAEDetector` (Вариационный Автоэнкодер)

*   **Используемые Признаки:**
    *   Работает со **списком** числовых признаков.
    *   Список задается параметром `features` в конфигурации (например, `"features": ["price", "freight_value"]`).
    *   Функция `common.engineer_features` для него **не** вызывается.
    *   Использует `StandardScaler`.
*   **Обучение (`train`):**
    *   Обучает вариационный автоэнкодер (PyTorch), минимизируя комбинированную функцию потерь (**ошибка реконструкции** + **KL-дивергенция**).
    *   Обучает `StandardScaler`.
    *   Вычисляет **порог аномальности (`threshold_`)** как **перцентиль** (например, 99-й) ошибки реконструкции на обучающих данных.
    *   Обучает **нормализатор Min-Max** для скоров (на основе ошибок реконструкции обучающих данных).
*   **Детекция (`detect`):**
    *   Применяет `StandardScaler`.
    *   Пропускает данные через обученный VAE.
    *   Вычисляет **ошибку реконструкции (MSE)** для каждой точки.
    *   Эта ошибка записывается в `anomaly_score`.
*   **Принятие решения (`is_anomaly`):**
    *   Сравнивает `anomaly_score` (ошибку реконструкции) с порогом `threshold_` (перцентилем), вычисленным при обучении.
    *   Если `anomaly_score >= threshold_`, то `is_anomaly` устанавливается в `True`.
    *   **Вывод:** Этот детектор **сам принимает решение** об аномальности на основе порога ошибки реконструкции.

### 5. `GraphAnomalyDetector` (На основе графовых метрик)

*   **Используемые Признаки:**
    *   Не использует параметр `features` из конфигурации.
    *   Строит граф (`networkx`) на основе данных `OrderItem` и связанных таблиц (`Order`, `Product`, `Customer`, `Seller`, etc.), используя их ID и атрибуты (например, `product_category_name`, `seller_state`).
    *   Функция `common.engineer_features` для него **не** вызывается.
*   **Обучение (`train`):**
    *   Строит граф на обучающих данных.
    *   Вычисляет значения **заранее определенных графовых метрик** для каждого узла `OrderItem` (например, `num_states` - разброс штатов продавцов в заказе, `num_categories` - разнообразие категорий в заказе, `seller_degree` - степень узла продавца).
    *   Находит и сохраняет **минимальное и максимальное значение** для каждой из этих метрик на обучающих данных.
    *   Нормализует каждую метрику к [0, 1] (используя сохраненные min/max).
    *   Комбинирует нормализованные метрики с заданными весами (например, `seller_state_weight`).
    *   Обучает **итоговый нормализатор Min-Max** для скоров (на основе этих комбинированных взвешенных скоров обучающих данных).
    *   **Не вычисляет** порог для определения аномальности.
*   **Детекция (`detect`):**
    *   Строит граф на новых данных.
    *   Для каждого `OrderItem` вычисляет сырые графовые метрики.
    *   Нормализует каждую метрику индивидуально (используя min/max, сохраненные при обучении).
    *   Вычисляет итоговый **взвешенный скор** на основе нормализованных метрик.
    *   Этот итоговый взвешенный скор записывается в `anomaly_score`.
*   **Принятие решения (`is_anomaly`):**
    *   **Всегда** устанавливает `is_anomaly = False`.
    *   **Вывод:** Этот детектор **не принимает сам решение** об аномальности. Его скор предназначен для использования в ансамбле, где он будет нормализован и сравнен с общим порогом. 